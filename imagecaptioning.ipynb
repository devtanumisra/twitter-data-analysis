{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import os\n",
        "from glob import glob"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "O6nxZd4cq-sU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **image Preprocess**"
      ],
      "metadata": {
        "id": "xVqZxkCSq-sd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data: https://www.kaggle.com/datasets/srbhshinde/flickr8k-sau\n",
        "# Data folders have been modified \n",
        "images_path = '../CaptionData/Images/'\n",
        "images = glob(images_path+'*.jpg')\n",
        "len(images)"
      ],
      "metadata": {
        "id": "V7OI3B0IxKXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images[:5]"
      ],
      "metadata": {
        "trusted": true,
        "id": "5ShBhcAXq-sk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for i in range(5):\n",
        "    plt.figure()\n",
        "    img = cv2.imread(images[i])\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    plt.imshow(img)"
      ],
      "metadata": {
        "trusted": true,
        "id": "aoxE449Mq-sl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications import ResNet50\n",
        "\n",
        "incept_model = ResNet50(include_top=True)"
      ],
      "metadata": {
        "trusted": true,
        "id": "dUb94Ssvq-sn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "last = incept_model.layers[-2].output\n",
        "modele = Model(inputs = incept_model.input,outputs = last)\n",
        "modele.summary()"
      ],
      "metadata": {
        "trusted": true,
        "id": "88jVEBl3q-sr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images_features = {}\n",
        "count = 0\n",
        "for i in images:\n",
        "    img = cv2.imread(i)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = cv2.resize(img, (224,224))\n",
        "    \n",
        "    img = img.reshape(1,224,224,3)\n",
        "    pred = modele.predict(img).reshape(2048,)\n",
        "        \n",
        "    img_name = i.split('/')[-1]\n",
        "    \n",
        "    images_features[img_name] = pred\n",
        "    \n",
        "    count += 1\n",
        "    \n",
        "    if count > 1499:\n",
        "        break\n",
        "        \n",
        "    elif count % 50 == 0:\n",
        "        print(count)\n",
        "    \n",
        "        \n",
        "    "
      ],
      "metadata": {
        "trusted": true,
        "id": "boOp5MRJq-st"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(images_features)"
      ],
      "metadata": {
        "trusted": true,
        "id": "u8PsPS-Xq-sx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Text Preprocess**"
      ],
      "metadata": {
        "id": "xxDHVR89q-sy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "caption_path = '../CaptionData/TextData/Flickr8k.token.txt'"
      ],
      "metadata": {
        "trusted": true,
        "id": "dk83dIk_q-sz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "captions = open(caption_path, 'rb').read().decode('utf-8').split('\\n')"
      ],
      "metadata": {
        "trusted": true,
        "id": "j44b1h0vq-s0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(captions)"
      ],
      "metadata": {
        "trusted": true,
        "id": "4ZKeHFVwq-s1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "captions_dict = {}\n",
        "for i in captions:\n",
        "    try:\n",
        "        img_name = i.split('\\t')[0][:-2] \n",
        "        caption = i.split('\\t')[1]\n",
        "        if img_name in images_features:\n",
        "            if img_name not in captions_dict:\n",
        "                captions_dict[img_name] = [caption]\n",
        "                \n",
        "            else:\n",
        "                captions_dict[img_name].append(caption)\n",
        "            \n",
        "    except:\n",
        "        pass"
      ],
      "metadata": {
        "trusted": true,
        "id": "D-qTW9Coq-s1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(captions_dict)"
      ],
      "metadata": {
        "trusted": true,
        "id": "dFuLp-A9q-s2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Visualize Images with captions**"
      ],
      "metadata": {
        "id": "eSNypTM0q-s3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for i in range(5):\n",
        "    plt.figure()\n",
        "    img_name = images[i]\n",
        "    \n",
        "    \n",
        "    img = cv2.imread(img_name)\n",
        "    \n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    plt.xlabel(captions_dict[img_name.split('/')[-1]])\n",
        "    plt.imshow(img)"
      ],
      "metadata": {
        "trusted": true,
        "id": "PORi4sjRq-s4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for k in images_features.keys():\n",
        "    plt.figure()\n",
        "    \n",
        "    img_name = '../CaptionData/Images/' + k\n",
        "    \n",
        "    \n",
        "    img = cv2.imread(img_name)\n",
        "    \n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    plt.xlabel(captions_dict[img_name.split('/')[-1]])\n",
        "    plt.imshow(img)\n",
        "    \n",
        "    break"
      ],
      "metadata": {
        "trusted": true,
        "id": "deOQIPtKq-s6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def preprocessed(txt):\n",
        "    modified = txt.lower()\n",
        "    modified = 'startofseq ' + modified + ' endofseq'\n",
        "    return modified\n",
        "    "
      ],
      "metadata": {
        "trusted": true,
        "id": "PfYezZDsq-s8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k,v in captions_dict.items():\n",
        "    for vv in v:\n",
        "        captions_dict[k][v.index(vv)] = preprocessed(vv)"
      ],
      "metadata": {
        "trusted": true,
        "id": "FdPvziVrq-s9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Create Vocabulary**"
      ],
      "metadata": {
        "id": "JTxoEyCWq-s-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count_words = {}\n",
        "for k,vv in captions_dict.items():\n",
        "    for v in vv:\n",
        "        for word in v.split():\n",
        "            if word not in count_words:\n",
        "\n",
        "                count_words[word] = 0\n",
        "\n",
        "            else:\n",
        "                count_words[word] += 1"
      ],
      "metadata": {
        "trusted": true,
        "id": "PVKpwCRFq-tA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(count_words)"
      ],
      "metadata": {
        "trusted": true,
        "id": "I29pN8-aq-tA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "THRESH = -1\n",
        "count = 1\n",
        "new_dict = {}\n",
        "for k,v in count_words.items():\n",
        "    if count_words[k] > THRESH:\n",
        "        new_dict[k] = count\n",
        "        count += 1\n",
        "        "
      ],
      "metadata": {
        "trusted": true,
        "id": "aEXZ7riSq-tB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(new_dict)"
      ],
      "metadata": {
        "trusted": true,
        "id": "owJ3tiwEq-tC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_dict['<OUT>'] = len(new_dict) "
      ],
      "metadata": {
        "trusted": true,
        "id": "9oJZqFYkq-tC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "captions_backup = captions_dict.copy()"
      ],
      "metadata": {
        "trusted": true,
        "id": "cOUfusraq-tD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "captions_dict = captions_backup.copy()"
      ],
      "metadata": {
        "trusted": true,
        "id": "EAlTOXd5q-tD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k, vv in captions_dict.items():\n",
        "    for v in vv:\n",
        "        encoded = []\n",
        "        for word in v.split():  \n",
        "            if word not in new_dict:\n",
        "                encoded.append(new_dict['<OUT>'])\n",
        "            else:\n",
        "                encoded.append(new_dict[word])\n",
        "\n",
        "\n",
        "        captions_dict[k][vv.index(v)] = encoded"
      ],
      "metadata": {
        "trusted": true,
        "id": "oTJZEjpoq-tE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "captions_dict"
      ],
      "metadata": {
        "trusted": true,
        "id": "rmUESFz-q-tE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "------------------------------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "U9mkDg_Kq-tF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Build Generator Function**"
      ],
      "metadata": {
        "id": "JA21C8C7q-tG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "trusted": true,
        "id": "g0rlbhXoq-tG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 0\n",
        "for k, vv in captions_dict.items():\n",
        "    for v in vv:\n",
        "        if len(v) > MAX_LEN:\n",
        "            MAX_LEN = len(v)\n",
        "            print(v)"
      ],
      "metadata": {
        "trusted": true,
        "id": "FrI7bDOAq-tI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN"
      ],
      "metadata": {
        "trusted": true,
        "id": "Qtes7qkjq-tI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "captions_dict"
      ],
      "metadata": {
        "trusted": true,
        "id": "KLppmSmFq-tI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Batch_size = 5000\n",
        "VOCAB_SIZE = len(new_dict)\n",
        "\n",
        "def generator(photo, caption):\n",
        "    n_samples = 0\n",
        "    \n",
        "    X = []\n",
        "    y_in = []\n",
        "    y_out = []\n",
        "    \n",
        "    for k, vv in caption.items():\n",
        "        for v in vv:\n",
        "            for i in range(1, len(v)):\n",
        "                X.append(photo[k])\n",
        "\n",
        "                in_seq= [v[:i]]\n",
        "                out_seq = v[i]\n",
        "\n",
        "                in_seq = pad_sequences(in_seq, maxlen=MAX_LEN, padding='post', truncating='post')[0]\n",
        "                out_seq = to_categorical([out_seq], num_classes=VOCAB_SIZE)[0]\n",
        "\n",
        "                y_in.append(in_seq)\n",
        "                y_out.append(out_seq)\n",
        "            \n",
        "    return X, y_in, y_out\n",
        "    \n",
        "    "
      ],
      "metadata": {
        "trusted": true,
        "id": "ZcpZw7pAq-tJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y_in, y_out = generator(images_features, captions_dict)"
      ],
      "metadata": {
        "trusted": true,
        "id": "UlX-4iHOq-tK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X), len(y_in), len(y_out)"
      ],
      "metadata": {
        "trusted": true,
        "id": "sIcabpHgq-tL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(X)\n",
        "y_in = np.array(y_in, dtype='float64')\n",
        "y_out = np.array(y_out, dtype='float64')\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "4glV7c5Cq-tM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape, y_in.shape, y_out.shape"
      ],
      "metadata": {
        "trusted": true,
        "id": "Hu6ozHu9q-tM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X[1510]"
      ],
      "metadata": {
        "trusted": true,
        "id": "A1P8wBLaq-tN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_in[2]"
      ],
      "metadata": {
        "trusted": true,
        "id": "cvN9tJK_q-tN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MODEL**"
      ],
      "metadata": {
        "id": "s-qsa4E2q-tO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.utils import plot_model\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Dropout\n",
        "from keras.layers.merge import add\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.layers import Dense, Flatten,Input, Convolution2D, Dropout, LSTM, TimeDistributed, Embedding, Bidirectional, Activation, RepeatVector,Concatenate\n",
        "from keras.models import Sequential, Model"
      ],
      "metadata": {
        "trusted": true,
        "id": "gwiPE74cq-tO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "ppHxiz7cq-tQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_size = 128\n",
        "max_len = MAX_LEN\n",
        "vocab_size = len(new_dict)\n",
        "\n",
        "image_model = Sequential()\n",
        "\n",
        "image_model.add(Dense(embedding_size, input_shape=(2048,), activation='relu'))\n",
        "image_model.add(RepeatVector(max_len))\n",
        "\n",
        "image_model.summary()\n",
        "\n",
        "language_model = Sequential()\n",
        "\n",
        "language_model.add(Embedding(input_dim=vocab_size, output_dim=embedding_size, input_length=max_len))\n",
        "language_model.add(LSTM(256, return_sequences=True))\n",
        "language_model.add(TimeDistributed(Dense(embedding_size)))\n",
        "\n",
        "language_model.summary()\n",
        "\n",
        "conca = Concatenate()([image_model.output, language_model.output])\n",
        "x = LSTM(128, return_sequences=True)(conca)\n",
        "x = LSTM(512, return_sequences=False)(x)\n",
        "x = Dense(vocab_size)(x)\n",
        "out = Activation('softmax')(x)\n",
        "model = Model(inputs=[image_model.input, language_model.input], outputs = out)\n",
        "\n",
        "# model.load_weights(\"../input/model_weights.h5\")\n",
        "model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "trusted": true,
        "id": "VxQ7k_Anq-tQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit([X, y_in], y_out, batch_size=512, epochs=50)"
      ],
      "metadata": {
        "trusted": true,
        "id": "KbkRjTMeq-tR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inv_dict = {v:k for k, v in new_dict.items()}"
      ],
      "metadata": {
        "trusted": true,
        "id": "cOhXtqWWq-tS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('model.h5')"
      ],
      "metadata": {
        "trusted": true,
        "id": "EIJJsmOVq-tS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights('mine_model_weights.h5')"
      ],
      "metadata": {
        "trusted": true,
        "id": "UtOigJ9Lq-tT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('vocab.npy', new_dict)"
      ],
      "metadata": {
        "trusted": true,
        "id": "rVnbnvjNq-tT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getImage(x):\n",
        "    \n",
        "    test_img_path = images[x]\n",
        "\n",
        "    test_img = cv2.imread(test_img_path)\n",
        "    test_img = cv2.cvtColor(test_img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    test_img = cv2.resize(test_img, (299,299))\n",
        "\n",
        "    test_img = np.reshape(test_img, (1,299,299,3))\n",
        "    \n",
        "    return test_img"
      ],
      "metadata": {
        "trusted": true,
        "id": "LGyvB3lAq-tT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Predictions**"
      ],
      "metadata": {
        "id": "CjGWX9Ixq-tU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "    \n",
        "    no = np.random.randint(1500,7000,(1,1))[0,0]\n",
        "    test_feature = modele.predict(getImage(no)).reshape(1,2048)\n",
        "    \n",
        "    test_img_path = images[no]\n",
        "    test_img = cv2.imread(test_img_path)\n",
        "    test_img = cv2.cvtColor(test_img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "\n",
        "    text_inp = ['startofseq']\n",
        "\n",
        "    count = 0\n",
        "    caption = ''\n",
        "    while count < 25:\n",
        "        count += 1\n",
        "\n",
        "        encoded = []\n",
        "        for i in text_inp:\n",
        "            encoded.append(new_dict[i])\n",
        "\n",
        "        encoded = [encoded]\n",
        "\n",
        "        encoded = pad_sequences(encoded, padding='post', truncating='post', maxlen=MAX_LEN)\n",
        "\n",
        "\n",
        "        prediction = np.argmax(model.predict([test_feature, encoded]))\n",
        "\n",
        "        sampled_word = inv_dict[prediction]\n",
        "\n",
        "        caption = caption + ' ' + sampled_word\n",
        "            \n",
        "        if sampled_word == 'endofseq':\n",
        "            break\n",
        "\n",
        "        text_inp.append(sampled_word)\n",
        "        \n",
        "    plt.figure()\n",
        "    plt.imshow(test_img)\n",
        "    plt.xlabel(caption)"
      ],
      "metadata": {
        "trusted": true,
        "id": "422QYCNQq-tU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "3eAvbHtbq-tW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "CP1waYz1q-tX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "WChPBN2Lq-tX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}